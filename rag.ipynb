{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df89be8f-2c49-4f4f-9503-2bff0b08a67a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df89be8f-2c49-4f4f-9503-2bff0b08a67a",
        "outputId": "3809aef6-5ca0-4f77-a5f7-4d3318e8a40b"
      },
      "outputs": [],
      "source": [
        "! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5258de38-0cc0-4d9d-a5ca-6e750ebe6976",
      "metadata": {
        "id": "5258de38-0cc0-4d9d-a5ca-6e750ebe6976"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feaccdca-1ab0-43b1-82c2-22e9cd27675b",
      "metadata": {
        "id": "feaccdca-1ab0-43b1-82c2-22e9cd27675b"
      },
      "source": [
        "`(3) API Keys`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1cd6453b-2721-491c-b979-1860d58d8cf5",
      "metadata": {
        "id": "1cd6453b-2721-491c-b979-1860d58d8cf5"
      },
      "outputs": [],
      "source": [
        "os.environ['LANGCHAIN_API_KEY'] = None\n",
        "os.environ[\"TAVILY_API_KEY\"] = None\n",
        "os.environ['OPENAI_API_KEY'] = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d1b6e2b-dd76-410d-b870-23e02564a665",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d1b6e2b-dd76-410d-b870-23e02564a665",
        "outputId": "b9224d01-9026-4dad-b1bb-288be7be6c3e"
      },
      "outputs": [],
      "source": [
        "#### INDEXING ####\n",
        "\n",
        "# Load blog\n",
        "import bs4\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "blog_docs = loader.load()\n",
        "\n",
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=50)\n",
        "\n",
        "# Make splits\n",
        "splits = text_splitter.split_documents(blog_docs)\n",
        "\n",
        "# Index\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "vectorstore = Chroma.from_documents(documents=splits,\n",
        "                                    embedding=OpenAIEmbeddings())\n",
        "\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FEgatS2IjHEZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEgatS2IjHEZ",
        "outputId": "aeafeb80-7dcd-49a6-a95a-0b6348bbe796"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain-community faiss-cpu\n",
        "!pip install rank_bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ROGT-E-hhUlV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROGT-E-hhUlV",
        "outputId": "7d800c36-50f2-4c3b-d89d-c83a4f4a6664"
      },
      "outputs": [],
      "source": [
        "#### INDEXING ####\n",
        "\n",
        "# Load blog\n",
        "import bs4\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "blog_docs = loader.load()\n",
        "\n",
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=50)\n",
        "\n",
        "# Make splits\n",
        "splits = text_splitter.split_documents(blog_docs)\n",
        "print(type(splits[-1]))\n",
        "\n",
        "# Index\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma, FAISS\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
        "from langchain.storage import InMemoryByteStore\n",
        "\n",
        "# store = InMemoryByteStore()\n",
        "\n",
        "\n",
        "faiss_index = FAISS.from_documents(splits, embedding=OpenAIEmbeddings())\n",
        "faiss_retriever = faiss_index.as_retriever()\n",
        "\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(splits)\n",
        "# bm25_retriever.add_texts(splits)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, faiss_retriever],\n",
        "                                       weights=[0.4, 0.6])\n",
        "\n",
        "query = \"What is task decomposition for LLM agents?\"\n",
        "relevant_documents = ensemble_retriever.get_relevant_documents(query)\n",
        "\n",
        "# Output the results\n",
        "for doc in relevant_documents:\n",
        "    print(type(doc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c72bbd12-f85c-4ed0-9dfa-8503afebfafa",
      "metadata": {
        "id": "c72bbd12-f85c-4ed0-9dfa-8503afebfafa"
      },
      "outputs": [],
      "source": [
        "# # Prompt\n",
        "# template = \"\"\"Here are the items that you need to grade based on the question, rubric and answer given. The items are formatted in the form 'Question #, question, rubric, answer':\n",
        "\n",
        "# \\n --- \\n {question} \\n --- \\n\n",
        "\n",
        "# Here is any available background question + answer pairs:\n",
        "\n",
        "# \\n --- \\n {q_a_pairs} \\n --- \\n\n",
        "\n",
        "# Here is additional context relevant to the question:\n",
        "\n",
        "# \\n --- \\n {context} \\n --- \\n\n",
        "\n",
        "# You are an agent that primarily uses the above context and any background question + answer pairs to grade the answer for the provided rubric item. \\n\n",
        "# The rubric item is provided to you where the points provided corresponds to if the rubric item is true in the student answer. That means the points in the rubric item, no matter if positive or negative, are given only if the rubric item is TRUE in the student answer. If the points is negative, and the rubric item is not satisfied, then give a score of 0. Your final output should be in the format \"score: reasoning\" and make sure the reasoning is succinct and to the point. The reasoning should also be focused on the current rubric item only, and it should be directed to the student in the proper tense. \\n\n",
        "# First, only use the rubric item to give the score, but if you are not confident, you can also use the above context and any background question + answer pairs to help grade the answer for the provided rubric item, but remember that the rubric item is your first and most reliable source of information. Think step by step and grade: \\n {question}\n",
        "# \"\"\"\n",
        "\n",
        "# decomposition_prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a20bf0d4-f567-4451-834d-a07190a3185e",
      "metadata": {
        "id": "a20bf0d4-f567-4451-834d-a07190a3185e"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def format_qa_pair(question, answer):\n",
        "    \"\"\"Format Q and A pair\"\"\"\n",
        "    formatted_string = \"\"\n",
        "    formatted_string += f\"Rubric Item: {question}\\nGrade and Feedback: {answer}\\n\\n\"\n",
        "    return formatted_string.strip()\n",
        "\n",
        "# llm\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# q_a_pairs = \"\"\n",
        "# answers = \"\"\n",
        "# for q in questions:\n",
        "#     # print(type(q))\n",
        "#     rag_chain = (\n",
        "#     {\"context\": itemgetter(\"question\") | retriever,\n",
        "#      \"question\": itemgetter(\"question\"),\n",
        "#      \"q_a_pairs\": itemgetter(\"q_a_pairs\")}\n",
        "#     | decomposition_prompt\n",
        "#     | llm\n",
        "#     | StrOutputParser())\n",
        "\n",
        "#     answer = rag_chain.invoke({\"question\":q,\"q_a_pairs\":q_a_pairs})\n",
        "#     q_a_pair = format_qa_pair(q,answer)\n",
        "#     q_a_pairs = q_a_pairs + \"\\n---\\n\"+  q_a_pair\n",
        "#     answers = answers + \"\\n---\\n\"+  answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aXkuBN4rdVZ3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXkuBN4rdVZ3",
        "outputId": "7f04e5b3-67b4-4439-84d7-60a04e2fe3f4"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-core langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "w178tojMZJQe",
      "metadata": {
        "id": "w178tojMZJQe"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import (\n",
        "    BaseMessage,\n",
        "    HumanMessage,\n",
        "    ToolMessage,\n",
        ")\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "def create_detector_agent(llm, system_message: str):\n",
        "    \"\"\"Create an agent.\"\"\"\n",
        "    ans = []\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"You are assuming the role of an AI-content detector. The messages in the conversation state will contain the question and student answer in the format 'question:answer', and you need to determine whether the answer contains AI-generated content. Provide the score as a JSON with exactly two keys: 'score' and 'lines'. The score should be a value between 0.0 and 100.0, where the higher the score is, the higher the percentage of AI-generated content exists in the student answer. The value for the 'lines' key should only cite the parts of the student answer where you can guarantee there is AI-content in the student answer, so it only contain content EXACTLY in the student answer and nothing else, I REPEAT nothing else. Make sure the content is all regarding what is written by the student. The lines output should be only taken from the student answer. Do not write anything other than that. If the answer is empty, output 0.1, and if there is no miniscule relation between the answer and question, output 0.0. There should be no preamble or explanation.\"\n",
        "                \" \\n{system_message}\",\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "    prompt = prompt.partial(system_message=system_message)\n",
        "    return prompt | llm | JsonOutputParser()\n",
        "\n",
        "\n",
        "def create_grader_agent(llm, system_message: str):\n",
        "    \"\"\"Create an agent.\"\"\"\n",
        "    ans = []\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"You are assuming the role of a student answer grader. You will be given a review of your grading, unless this is the first iteration of grading the answer. If the review exists, and if it starts with 'FINAL GRADE:', then it thinks your grading for that specific rubric item is correct, else it has some improvements that you can take into account. If you think the review improvement advice is not correct, do not follow it, but keep in mind, the reviewer is trying to help, and take its advice seriously. Here are the items that you need to grade based on the question, rubric and answer given. The rubric items are formatted in the form 'Question #, question, rubric, answer'. You will be given this item, plus the previous rubric items+grading scores, and also context related to the rubric item. \\n --- \\n  You are an agent that primarily uses the rubric item to grade the answer for the provided rubric item. \\n The rubric item is provided to you where the points provided corresponds to if the rubric item is true in the student answer. That means the points in the rubric item, no matter if positive or negative, are given only if the rubric item is TRUE in the student answer. If the points is negative, and the rubric item is not satisfied, then give a score of 0. Your final output should be in the format 'score: reasoning' and make sure the reasoning is succinct and to the point. The reasoning should also be focused on the current rubric item only, and it should be directed to the student in the proper tense. \\n First, only use the rubric item to give the score, but if you are not confident, you can also use the above context and any background question + answer pairs to help grade the answer for the provided rubric item, but remember that the rubric item is your first and most reliable source of information. If you are giving the student the points, then don't tell what is wrong with it. Just explain why the student did or did not get the points, don't give unneccesary information, so it is concise. Always use the rubric as final call. Think step by step and grade the student answer using the rubric and review as advice. The rubric is the final decision. Go with the rubric.\"\n",
        "                \" \\n{system_message}\",\n",
        "            ),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        ]\n",
        "    )\n",
        "    prompt = prompt.partial(system_message=system_message)\n",
        "    return prompt | llm\n",
        "\n",
        "def create_reviewer_agent(llm, system_message: str):\n",
        "    \"\"\"Create an agent.\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"Your role is to review the points and reasoning given by the grader, and ensure that all information is correct and factual. The information in the reasoning should primarily be built from the rubric, and the grader's score and reasoning respectively.  \\n --- \\n The rubric items are formatted in the form 'Question #, question, rubric, answer, grade'. You will be given this item, and also context related to the rubric item from the database we have. \\n --- \\n Read the reasoning carefully to make sure no hallucination and distraction is there. If you think there is a mistake in the grading regarding the points given, object. Think step by step and review the grading and reasoning for the rubric item in the messages, and make your review concise. If there is no mistake in the grade of a rubric item, start your review with 'FINAL POINTS:', otherwise start with 'WRONG POINTS:', and you must start with either. The conversation state will contains the grades in the format 'score, reasoning', so if the score is correct, do not output 'WRONG POINTS:'. If you think the grader gave the correct points, just make sure mentions what the rubric expected. The beginning of the review is only two options: 'FINAL POINTS:' if the grade gave the correct points, and 'WRONG POINTS:' if the grade did not give the correct points\"\n",
        "                \" \\n{system_message}\",\n",
        "            ),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        ]\n",
        "    )\n",
        "    prompt = prompt.partial(system_message=system_message)\n",
        "    return prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "JfR1RX9OgiIt",
      "metadata": {
        "id": "JfR1RX9OgiIt"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "from typing import Annotated, Sequence\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "# This defines the object that is passed between each node\n",
        "# in the graph. We will create different nodes for each agent and tool\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    sender: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "8luJFB1ZAP16",
      "metadata": {
        "id": "8luJFB1ZAP16"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# Prompt to decompose rubric items into list of elements where each element contains Question #, Question, Rubric, Student Answer; each element is separated based on rubric item\"\n",
        "template = \"\"\"You are a helpful assistant that divides the rubric/answer key and the student answers into separate entries. Each entry includes the question number, question, rubric item on what content would reward/deduct points for the answer, and the entire answer. Do not output multiple rubric items at once. \\n\n",
        "The goal is to break down the rubric into a set of rubric items that can be checked in isolation. \\n\n",
        "Divide the rubric into separate items. For example if the question numbers are 1, 2a, 2b, 2c, 3, 4, each question will be divided and then the following rubric items and the student answer will be for the question. Ensure that the number of items for each question corresponds to the number of rubric items where points are rewarded or deducted. Do nut make up rubric items. Follow the following rubric entirely. You are grounded by this rubric, so everything comes from this rubric.  \\n\n",
        "Strictly format the division of the rubric into 'question #: question: rubric item: student answer', and if there are multiple rubric items for each question, then separate each item into separate entries, but maintain the same question number, question and answer. Therefore, each rubric item for the same question should have the same question number, question, and answer.  \\n\n",
        "Make sure the question #, question, and rubric item, and it follows the rubric entirely to a tee. The answer must be grounded as well, and use only the student answers provided to divide them. Each element in the list of rubric items should consist of an non-empty string of a rubric item, and each element should have the question #, question, rubric item and answer in one string. If the student answer is empty, simply add 'N/A' at the end of the rubric item. Make sure there is only one rubric point item per entry, and do not repeat entries. Here is the entire rubric list  {question}. Here are the student answers {answer}\\n\n",
        "Do not have empty rubric items. Do not output the entire rubric at the beginning of this decomposition. I only want sub-rubric items. Output (n rubric items):\"\"\"\n",
        "prompt_decomposition = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "JI7YG2JxQe5p",
      "metadata": {
        "id": "JI7YG2JxQe5p"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Generate the questions and answers in the format we would like -- 'question #: question: rubric item: student answer'\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "generate_queries_decomposition = ( prompt_decomposition | llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
        "\n",
        "question = \"1. What are the main components of an LLM-powered autonomous agent system? Mentions 'rag': 1 point, Mentions 'decomposition': 1 point, If any other component other than 'rag' and 'decomposition', give a score of -1: -1 point \\n 2a. What are the main components of an AI-powered autonomous agent system? Mentions beta: 1 point, Mentions cloud: 1 point\"\n",
        "answer = \"1. I think they are rag, zeta, cheta, neta, decomposition \\n 2a. \"\n",
        "questions = generate_queries_decomposition.invoke({\"question\":question, \"answer\":answer})\n",
        "\n",
        "generate_questions = ( get_questions | llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
        "\n",
        "qs = generate_questions.invoke({\"question\":question, \"answer\":answer})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4sIC5nzigiRc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sIC5nzigiRc",
        "outputId": "135a68d5-3e9e-419b-968e-2779990be4a4"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "\n",
        "from langchain_core.messages import AIMessage\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "#Helper function to create a node for AI detector agent\n",
        "def detector_node(state, agent, name, items):\n",
        "    total_score = 0.0\n",
        "    i = 0\n",
        "    lines = []\n",
        "    print(name)\n",
        "    for question in questions:\n",
        "      i += 1\n",
        "      current_state = {\n",
        "            \"messages\": [HumanMessage(content=question)],\n",
        "            \"sender\": name,\n",
        "      }\n",
        "      result = agent.invoke(current_state)\n",
        "      total_score += result[\"score\"]\n",
        "      lines.append(result[\"lines\"])\n",
        "    total_score /= i\n",
        "    return {\"score\": total_score, \"lines\": lines, \"sender\": name, \"messages\": []}\n",
        "\n",
        "# Helper function to create a node for both grader and reviewer agents\n",
        "def agent_node(state, agent, name, questions):\n",
        "    messages = state[\"messages\"]\n",
        "    q_a_pairs = \"\"\n",
        "    answers = []\n",
        "    prev_q = questions[0]\n",
        "    # print(questions)\n",
        "    for i, question in enumerate(questions):\n",
        "      # if answers:\n",
        "        # q_a_pair = format_qa_pair(prev_q,answers[-1])\n",
        "        # q_a_pairs = q_a_pairs + \"\\n---\\n\"+  q_a_pair\n",
        "      if messages:\n",
        "        if name == \"Grader\":\n",
        "          # get the last grade and review \n",
        "          current_state = {\n",
        "                \"messages\": [HumanMessage(content=question)] + [messages[-len(questions)+i]],\n",
        "                \"sender\": name,\n",
        "                # \"q_a_pairs\": q_a_pairs,\n",
        "                # \"context\": ensemble_retriever.invoke(q)\n",
        "          }\n",
        "        # get the last grade given to review \n",
        "        else:\n",
        "          current_state = {\n",
        "                \"messages\": [HumanMessage(content=question)] + [messages[-len(questions)+i]],\n",
        "                \"sender\": name,\n",
        "                # \"q_a_pairs\": q_a_pairs,\n",
        "                # \"context\": ensemble_retriever.invoke(q)\n",
        "          }\n",
        "      else:\n",
        "        current_state = {\n",
        "            \"messages\": [HumanMessage(content=question)],\n",
        "            \"sender\": name,\n",
        "            # \"q_a_pairs\": q_a_pairs,\n",
        "            # \"context\": ensemble_retriever.invoke(q)\n",
        "        }\n",
        "      prev_q = question\n",
        "      result = agent.invoke(current_state)\n",
        "      answers.append(result.content)\n",
        "    # We convert the agent output into a format that is suitable to append to the global state\n",
        "    # all_answers = \"\\n\".join(answers)\n",
        "    # result = AIMessage(content=all_answers, **result.dict(exclude={\"content\", \"type\", \"name\"}), name=name)\n",
        "    # result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
        "    if name == \"Reviewer\":\n",
        "      return {\n",
        "        \"messages\": [message + \" \" + answer for message,answer in zip(messages[-len(answers):], answers)],\n",
        "        \"sender\": name,\n",
        "      }\n",
        "    if name == \"Grader\":\n",
        "      return {\n",
        "          \"messages\": answers,\n",
        "          \"sender\": name,\n",
        "      }\n",
        "\n",
        "# LLM utilizzed -- GPT 4o mini\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.1)\n",
        "\n",
        "# AI Detector agent and node\n",
        "detector_agent = create_detector_agent(\n",
        "    llm,\n",
        "    system_message=\"You should determine whether there is AI-content in the student answers with a score from [0.0 - 100.0], which is the magnitude of AI-content generation. In the lines you output for the AI-generation, make sure those lines are actually in the student answer and no hallucination is there. If you don't think there is AI-generated content, do not add anything to the lines.\",\n",
        ")\n",
        "detector_node = functools.partial(detector_node, agent=detector_agent, name=\"Detector\", items=qs)\n",
        "\n",
        "# Grader agent and node\n",
        "grader_agent = create_grader_agent(\n",
        "    llm,\n",
        "    system_message=\"You should grade the student answers based on the rubric to the best of your ability. Do not go against the rubric information and assume anything on your own. Do not assume typos, go with what is given to you. Treat each rubric item as a condition, and negative points should be rewarded if the condition is satisfied. Do not take semantics of the rubric into account. Rubric is the truth. Scores can only be 0 or the points shown in the rubric item. \",\n",
        ")\n",
        "grader_node = functools.partial(agent_node, agent=grader_agent, name=\"Grader\", questions=questions)\n",
        "\n",
        "# Reviewer agent and node\n",
        "review_agent = create_reviewer_agent(\n",
        "    llm,\n",
        "    system_message=\"You should make sure the grader follows the rubric primarily. Do not go against the rubric information and assume anything on your own. If the answer satisfies the rubric, do not give a reason to not give the point. Only follow the current rubric item. Other rubric items should not affect your judgement.Do not assume typos, go with what is given to you. If the points are rewarded, do not mention anything in the explanation, except the fact that it satisfied whatever is on the rubric. For negative rubric points, treat it as a binary option between 0 and the negative value, so if the rubric condition is true, then give it the negative points, else if the rubric requirement is not satisfied, give it 0 if there are negative points. If the points rewarded align, then make sure to start with 'FINAL POINTS:', else start with 'WRONG POINTS:' 'WRONG POINTS:' is given only if the score given by you is not the same as the score given by the grader, do not misuse it.\"\n",
        ")\n",
        "reviewer_node = functools.partial(agent_node, agent=review_agent, name=\"Reviewer\", questions=questions)\n",
        "# print(questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "tbBzIlJggiUF",
      "metadata": {
        "id": "tbBzIlJggiUF"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "\n",
        "def router(state):\n",
        "    \"\"\"\n",
        "    Route the flow based on the state. Only a specific agent can end the process.\n",
        "\n",
        "    Parameters:\n",
        "    - state: The current state containing the messages.\n",
        "    - end_agent: The name or identifier of the agent allowed to end the process.\n",
        "\n",
        "    Returns:\n",
        "    - str: \"call_tool\", END, or \"continue\" based on the state.\n",
        "    \"\"\"\n",
        "    if state[\"sender\"] == \"Detector\":\n",
        "      if state[\"score\"] >= 80.0:\n",
        "        return END\n",
        "      return \"continue\"\n",
        "    if state[\"sender\"] == \"Reviewer\" or state[\"sender\"] == \"Grader\":\n",
        "      messages = state[\"messages\"]\n",
        "      if not \"WRONG POINTS\" in \" \".join(messages[-len(questions):]) and state[\"sender\"] == \"Reviewer\":\n",
        "          # Only the specified agent is allowed to end the process\n",
        "          return END\n",
        "\n",
        "      return \"continue\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "ihRWwhxvgiWw",
      "metadata": {
        "id": "ihRWwhxvgiWw"
      },
      "outputs": [],
      "source": [
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"Detector\", detector_node)\n",
        "workflow.add_node(\"Grader\", grader_node)\n",
        "workflow.add_node(\"Reviewer\", reviewer_node)\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"Detector\",\n",
        "    router,\n",
        "    {\"continue\": \"Grader\", END: END},\n",
        ")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"Grader\",\n",
        "    router,\n",
        "    {\"continue\": \"Reviewer\", END: END},\n",
        ")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"Reviewer\",\n",
        "    router,\n",
        "    {\"continue\": \"Grader\", END: END},\n",
        ")\n",
        "\n",
        "workflow.add_edge(START, \"Detector\")\n",
        "graph = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pbT6KKIzEbri",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbT6KKIzEbri",
        "outputId": "6c7b7321-7d15-4274-f4e5-598882908f04"
      },
      "outputs": [],
      "source": [
        "events = graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "        ],\n",
        "    },\n",
        "    # Maximum number of steps to take in the graph\n",
        "    {\"recursion_limit\": 10},\n",
        ")\n",
        "\n",
        "try:\n",
        "  for s in events:\n",
        "    print(s)\n",
        "    print(\"----\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(f\"final grade\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "stnVUawreVyT",
      "metadata": {
        "id": "stnVUawreVyT"
      },
      "outputs": [],
      "source": [
        "### Search\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "web_search_tool = TavilySearchResults(k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "PF2UqcUSeV0o",
      "metadata": {
        "id": "PF2UqcUSeV0o"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# Decomposition\n",
        "template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
        "The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \\n\n",
        "Generate multiple search queries related to: {question} \\n\n",
        "Output (3 queries):\"\"\"\n",
        "prompt_decomposition = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "dpGFU_BteV3F",
      "metadata": {
        "id": "dpGFU_BteV3F"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# LLM\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "# Chain\n",
        "generate_queries_decomposition = ( prompt_decomposition | llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
        "\n",
        "# Run\n",
        "questions = generate_queries_decomposition.invoke({\"question\":question})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kP_f4K7hj0uL",
      "metadata": {
        "id": "kP_f4K7hj0uL"
      },
      "outputs": [],
      "source": [
        "questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f_iCk0Rnj-zL",
      "metadata": {
        "id": "f_iCk0Rnj-zL"
      },
      "outputs": [],
      "source": [
        "### Retrieval Grader\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "# LLM\n",
        "# local_llm = \"llama3.1\"\n",
        "# llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"You are a grader assessing relevance\n",
        "    of a retrieved document to a user question. If the document contains keywords related to the user question,\n",
        "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals.\n",
        "\n",
        "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
        "    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\n",
        "\n",
        "    Here is the retrieved document:\n",
        "    {document}\n",
        "\n",
        "    Here is the user question:\n",
        "    {question}\n",
        "    \"\"\",\n",
        "    input_variables=[\"question\", \"document\"],\n",
        ")\n",
        "\n",
        "retrieval_grader = prompt | llm | JsonOutputParser()\n",
        "question = \"What are the main components of an LLM-powered autonomous agent system?\"\n",
        "docs = retriever.invoke(question)\n",
        "doc_txt = docs[1].page_content\n",
        "print(\n",
        "    f'Is our answer relevant to the question asked: {retrieval_grader.invoke({\"question\": question, \"document\": doc_txt})}'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JWsvDVNTMDBO",
      "metadata": {
        "id": "JWsvDVNTMDBO"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "\n",
        "prompt_rag = hub.pull(\"rlm/rag-prompt\")\n",
        "print(prompt_rag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "TWYqp7sPj0w3",
      "metadata": {
        "id": "TWYqp7sPj0w3"
      },
      "outputs": [],
      "source": [
        "# Answer each sub-question individually\n",
        "\n",
        "from langchain import hub\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import Document\n",
        "\n",
        "# RAG prompt\n",
        "prompt_rag = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "def retrieve_and_rag(question,prompt_rag,sub_question_generator_chain):\n",
        "    \"\"\"RAG on each sub-question\"\"\"\n",
        "\n",
        "    # Use our decomposition /\n",
        "    sub_questions = sub_question_generator_chain.invoke({\"question\":question})\n",
        "\n",
        "    # Initialize a list to hold RAG chain results\n",
        "    rag_results = []\n",
        "\n",
        "    for sub_question in sub_questions:\n",
        "        filtered_docs = []\n",
        "        # Retrieve documents for each sub-question\n",
        "        retrieved_docs = retriever.get_relevant_documents(sub_question)\n",
        "        for d in retrieved_docs:\n",
        "          score = retrieval_grader.invoke(\n",
        "              {\"question\": question, \"document\": d.page_content}\n",
        "          )\n",
        "          grade = score[\"score\"]\n",
        "          if grade.lower() == \"yes\":\n",
        "              # print(\"RELEVANT DOC\")\n",
        "              filtered_docs.append(d)\n",
        "          else:\n",
        "              # print(\"NOT RELEVANT\")\n",
        "              web_search = \"Yes\"\n",
        "              continue\n",
        "        if web_search == \"Yes\":\n",
        "          docs = web_search_tool.invoke({\"query\": question})\n",
        "          web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
        "          web_results = Document(page_content=web_results)\n",
        "          filtered_docs.append(web_results)\n",
        "\n",
        "        # Use retrieved documents and sub-question in RAG chain\n",
        "        answer = (prompt_rag | llm | StrOutputParser()).invoke({\"context\": retrieved_docs,\n",
        "                                                                \"question\": sub_question})\n",
        "        rag_results.append(answer)\n",
        "\n",
        "    return rag_results,sub_questions\n",
        "\n",
        "# Wrap the retrieval and RAG process in a RunnableLambda for integration into a chain\n",
        "answers, questions = retrieve_and_rag(question, prompt_rag, generate_queries_decomposition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RWqdKwgwj0zj",
      "metadata": {
        "id": "RWqdKwgwj0zj"
      },
      "outputs": [],
      "source": [
        "def format_qa_pairs(questions, answers):\n",
        "    \"\"\"Format Q and A pairs\"\"\"\n",
        "\n",
        "    formatted_string = \"\"\n",
        "    for i, (question, answer) in enumerate(zip(questions, answers), start=1):\n",
        "        formatted_string += f\"Question {i}: {question}\\nAnswer {i}: {answer}\\n\\n\"\n",
        "    return formatted_string.strip()\n",
        "\n",
        "context = format_qa_pairs(questions, answers)\n",
        "\n",
        "# Prompt\n",
        "template = \"\"\"Here is a set of Q+A pairs:\n",
        "\n",
        "{context}\n",
        "\n",
        "Use these to synthesize an answer to the question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "final_rag_chain = (\n",
        "    prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "final_rag_chain.invoke({\"context\":context,\"question\":question})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
